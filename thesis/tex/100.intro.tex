\documentclass[../thesis]{subfiles}

\begin{document}
	\chapter{Introduction}
	\label{chp:intro}

	\tdi{Context: The evolution of multiprocessing systems}
	\tdi{talk about SISD, SIMD \& MIMD}

	\section{Motivation and Goals}
	Previous work on this algorithm has been focused mainly on implementing it in a \cpu shared memory environment; heterogeneous distributed memory environments are still unexplored. Also, other linear algebra projects oriented at \gpus lack implementations for this algorithm. The resources made available in the recent hardware accelerators hold great potential to improve performance.

	This dissertation intends to extend the implementation of the matrix square root algorithm to heterogeneous platforms in order to achieve a higher degree of efficiency. It is particularly interesting to study the performance of this algorithm using massively parallel hardware accelerators.

	Throughout this dissertation, three implementations of the core process behind the matrix square root algorithm are proposed. The first, targeted for a multicore environment provides a first approach to the algorithm, the typical naive implementation. It also allows to port the implementations described in previous work to a more familiar open source environment. The second implementation is meant to use the new Intel Xeon Phi coprocessor, thus putting the claims made by Intel to the test. Lastly, the third implementation is targeted for CUDA-enabled \gpus.

	Each implementation is evaluated quantitatively. The multicore implementation provides a scalability test to help analyse the behaviour of the algorithm, while the other two provide an overview of the computation impact of the algorithm when executed in an hardware accelerator.

	\section{Document Organization}
	\Cref{chp:techbg,chp:case} provide the background information required to conveniently contextualize the reader. In particular, \cref{chp:techbg} provides an overview over the evolution of \hpc, the hardware characteristics of heterogeneous platforms and the challenges faced by programmers in this area. It also covers some tools to aid with these issues.

	The following chapters focus on the three mentioned implementations. \Cref{chp:multicore} describes the multicore implementations and further contextualizes the reader with the case study. It also presents the scalability test results and the consequent analysis. \Cref{chp:mic} focuses on the implementation target for the Intel \mic architecture, the results obtained and optimizations for a better tuning. In a similar fashion, \cref{chp:cuda} does the same for the CUDA implementation.

	Lastly, \cref{chp:conclusions,chp:futurework} present the conclusions of this dissertation and suggestions for future work, including further optimization opportunities and identified unexplored approaches.

	\tdi{Context: The evolution of the matrix square root}
	\tdi{Terminology}
	\tdi{Motivation: why extend the matrix square root to other systems}
	\tdi{Objectives: implement the matrix square root using accelerators}
\end{document}
